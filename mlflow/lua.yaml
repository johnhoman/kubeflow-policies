apiVersion: v1
kind: ConfigMap
metadata:
  name: lua.lib
  namespace: kubeflow
data:
  JSON.lua: "-- -*- coding: utf-8 -*-\n--\n-- Simple JSON encoding and decoding in
    pure Lua.\n--\n-- Copyright 2010-2017 Jeffrey Friedl\n-- http://regex.info/blog/\n--
    Latest version: http://regex.info/blog/lua/json\n--\n-- This code is released
    under a Creative Commons CC-BY \"Attribution\" License:\n-- http://creativecommons.org/licenses/by/3.0/deed.en_US\n--\n--
    It can be used for any purpose so long as:\n--    1) the copyright notice above
    is maintained\n--    2) the web-page links above are maintained\n--    3) the
    'AUTHOR_NOTE' string below is maintained\n--\nlocal VERSION = '20170927.26' --
    version history at end of file\nlocal AUTHOR_NOTE = \"-[ JSON.lua package by Jeffrey
    Friedl (http://regex.info/blog/lua/json) version 20170927.26 ]-\"\n\n--\n-- The
    'AUTHOR_NOTE' variable exists so that information about the source\n-- of the
    package is maintained even in compiled versions. It's also\n-- included in OBJDEF
    below mostly to quiet warnings about unused variables.\n--\nlocal OBJDEF = {\n
    \  VERSION      = VERSION,\n   AUTHOR_NOTE  = AUTHOR_NOTE,\n}\n\n\n--\n-- Simple
    JSON encoding and decoding in pure Lua.\n-- JSON definition: http://www.json.org/\n--\n--\n--
    \  JSON = assert(loadfile \"JSON.lua\")() -- one-time load of the routines\n--\n--
    \  local lua_value = JSON:decode(raw_json_text)\n--\n--   local raw_json_text
    \   = JSON:encode(lua_table_or_value)\n--   local pretty_json_text = JSON:encode_pretty(lua_table_or_value)
    -- \"pretty printed\" version for human readability\n--\n--\n--\n-- DECODING (from
    a JSON string to a Lua table)\n--\n--\n--   JSON = assert(loadfile \"JSON.lua\")()
    -- one-time load of the routines\n--\n--   local lua_value = JSON:decode(raw_json_text)\n--\n--
    \  If the JSON text is for an object or an array, e.g.\n--     { \"what\": \"books\",
    \"count\": 3 }\n--   or\n--     [ \"Larry\", \"Curly\", \"Moe\" ]\n--\n--   the
    result is a Lua table, e.g.\n--     { what = \"books\", count = 3 }\n--   or\n--
    \    { \"Larry\", \"Curly\", \"Moe\" }\n--\n--\n--   The encode and decode routines
    accept an optional second argument,\n--   \"etc\", which is not used during encoding
    or decoding, but upon error\n--   is passed along to error handlers. It can be
    of any type (including nil).\n--\n--\n--\n-- ERROR HANDLING DURING DECODE\n--\n--
    \  With most errors during decoding, this code calls\n--\n--      JSON:onDecodeError(message,
    text, location, etc)\n--\n--   with a message about the error, and if known, the
    JSON text being\n--   parsed and the byte count where the problem was discovered.
    You can\n--   replace the default JSON:onDecodeError() with your own function.\n--\n--
    \  The default onDecodeError() merely augments the message with data\n--   about
    the text and the location (and, an 'etc' argument had been\n--   provided to decode(),
    its value is tacked onto the message as well),\n--   and then calls JSON.assert(),
    which itself defaults to Lua's built-in\n--   assert(), and can also be overridden.\n--\n--
    \  For example, in an Adobe Lightroom plugin, you might use something like\n--\n--
    \         function JSON:onDecodeError(message, text, location, etc)\n--             LrErrors.throwUserError(\"Internal
    Error: invalid JSON data\")\n--          end\n--\n--   or even just\n--\n--          function
    JSON.assert(message)\n--             LrErrors.throwUserError(\"Internal Error:
    \" .. message)\n--          end\n--\n--   If JSON:decode() is passed a nil, this
    is called instead:\n--\n--      JSON:onDecodeOfNilError(message, nil, nil, etc)\n--\n--
    \  and if JSON:decode() is passed HTML instead of JSON, this is called:\n--\n--
    \     JSON:onDecodeOfHTMLError(message, text, nil, etc)\n--\n--   The use of the
    'etc' argument allows stronger coordination between\n--   decoding and error reporting,
    especially when you provide your own\n--   error-handling routines. Continuing
    with the the Adobe Lightroom\n--   plugin example:\n--\n--          function JSON:onDecodeError(message,
    text, location, etc)\n--             local note = \"Internal Error: invalid JSON
    data\"\n--             if type(etc) = 'table' and etc.photo then\n--                note
    = note .. \" while processing for \" .. etc.photo:getFormattedMetadata('fileName')\n--
    \            end\n--             LrErrors.throwUserError(note)\n--          end\n--\n--
    \           :\n--            :\n--\n--          for i, photo in ipairs(photosToProcess)
    do\n--               :             \n--               :             \n--               local
    data = JSON:decode(someJsonText, { photo = photo })\n--               :             \n--
    \              :             \n--          end\n--\n--\n--\n--   If the JSON text
    passed to decode() has trailing garbage (e.g. as with the JSON \"[123]xyzzy\"),\n--
    \  the method\n--\n--       JSON:onTrailingGarbage(json_text, location, parsed_value,
    etc)\n--\n--   is invoked, where:\n--\n--       'json_text' is the original JSON
    text being parsed,\n--       'location' is the count of bytes into 'json_text'
    where the garbage starts (6 in the example),\n--       'parsed_value' is the Lua
    result of what was successfully parsed ({123} in the example),\n--       'etc'
    is as above.\n--\n--   If JSON:onTrailingGarbage() does not abort, it should return
    the value decode() should return,\n--   or nil + an error message.\n--\n--     local
    new_value, error_message = JSON:onTrailingGarbage()\n--\n--   The default JSON:onTrailingGarbage()
    simply invokes JSON:onDecodeError(\"trailing garbage\"...),\n--   but you can
    have this package ignore trailing garbage via\n--\n--      function JSON:onTrailingGarbage(json_text,
    location, parsed_value, etc)\n--         return parsed_value\n--      end\n--\n--\n--
    DECODING AND STRICT TYPES\n--\n--   Because both JSON objects and JSON arrays
    are converted to Lua tables,\n--   it's not normally possible to tell which original
    JSON type a\n--   particular Lua table was derived from, or guarantee decode-encode\n--
    \  round-trip equivalency.\n--\n--   However, if you enable strictTypes, e.g.\n--\n--
    \     JSON = assert(loadfile \"JSON.lua\")() --load the routines\n--      JSON.strictTypes
    = true\n--\n--   then the Lua table resulting from the decoding of a JSON object
    or\n--   JSON array is marked via Lua metatable, so that when re-encoded with\n--
    \  JSON:encode() it ends up as the appropriate JSON type.\n--\n--   (This is not
    the default because other routines may not work well with\n--   tables that have
    a metatable set, for example, Lightroom API calls.)\n--\n--\n-- ENCODING (from
    a lua table to a JSON string)\n--\n--   JSON = assert(loadfile \"JSON.lua\")()
    -- one-time load of the routines\n--\n--   local raw_json_text    = JSON:encode(lua_table_or_value)\n--
    \  local pretty_json_text = JSON:encode_pretty(lua_table_or_value) -- \"pretty
    printed\" version for human readability\n--   local custom_pretty    = JSON:encode(lua_table_or_value,
    etc, { pretty = true, indent = \"|  \", align_keys = false })\n--\n--   On error
    during encoding, this code calls:\n--\n--     JSON:onEncodeError(message, etc)\n--\n--
    \  which you can override in your local JSON object. Also see \"HANDLING UNSUPPORTED
    VALUE TYPES\" below.\n--\n--   The 'etc' in the error call is the second argument
    to encode() and encode_pretty(), or nil if it wasn't provided.\n--\n--\n--\n--\n--
    ENCODING OPTIONS\n--\n--   An optional third argument, a table of options, can
    be provided to encode().\n--\n--       encode_options =  {\n--           -- options
    for making \"pretty\" human-readable JSON (see \"PRETTY-PRINTING\" below)\n--
    \          pretty         = true,   -- turn pretty formatting on\n--           indent
    \        = \"   \",  -- use this indent for each level of an array/object\n--
    \          align_keys     = false,  -- if true, align the keys in a way that sounds
    like it should be nice, but is actually ugly\n--           array_newline  = false,
    \ -- if true, array elements become one to a line rather than inline\n--           \n--
    \          -- other output-related options\n--           null           = \"\\0\",
    \  -- see \"ENCODING JSON NULL VALUES\" below\n--           stringsAreUtf8 = false,
    \ -- see \"HANDLING UNICODE LINE AND PARAGRAPH SEPARATORS FOR JAVA\" below\n--
    \      }\n--  \n--       json_string = JSON:encode(mytable, etc, encode_options)\n--\n--\n--\n--
    For reference, the defaults are:\n--\n--           pretty         = false\n--
    \          null           = nil,\n--           stringsAreUtf8 = false,\n--\n--\n--\n--
    PRETTY-PRINTING\n--\n--   Enabling the 'pretty' encode option helps generate human-readable
    JSON.\n--\n--     pretty = JSON:encode(val, etc, {\n--                                       pretty
    = true,\n--                                       indent = \"   \",\n--                                       align_keys
    = false,\n--                                     })\n--\n--   encode_pretty()
    is also provided: it's identical to encode() except\n--   that encode_pretty()
    provides a default options table if none given in the call:\n--\n--       { pretty
    = true, indent = \"  \", align_keys = false, array_newline = false }\n--\n--   For
    example, if\n--\n--      JSON:encode(data)\n--\n--   produces:\n--\n--      {\"city\":\"Kyoto\",\"climate\":{\"avg_temp\":16,\"humidity\":\"high\",\"snowfall\":\"minimal\"},\"country\":\"Japan\",\"wards\":11}\n--\n--
    \  then\n--\n--      JSON:encode_pretty(data)\n--\n--   produces:\n--\n--      {\n--
    \       \"city\": \"Kyoto\",\n--        \"climate\": {\n--          \"avg_temp\":
    16,\n--          \"humidity\": \"high\",\n--          \"snowfall\": \"minimal\"\n--
    \       },\n--        \"country\": \"Japan\",\n--        \"wards\": 11\n--      }\n--\n--
    \  The following lines all return identical strings:\n--       JSON:encode_pretty(data)\n--
    \      JSON:encode_pretty(data, nil, { pretty = true, indent = \"  \", align_keys
    = false, array_newline = false})\n--       JSON:encode_pretty(data, nil, { pretty
    = true, indent = \"  \" })\n--       JSON:encode       (data, nil, { pretty =
    true, indent = \"  \" })\n--\n--   An example of setting your own indent string:\n--\n--
    \    JSON:encode_pretty(data, nil, { pretty = true, indent = \"|    \" })\n--\n--
    \  produces:\n--\n--      {\n--      |    \"city\": \"Kyoto\",\n--      |    \"climate\":
    {\n--      |    |    \"avg_temp\": 16,\n--      |    |    \"humidity\": \"high\",\n--
    \     |    |    \"snowfall\": \"minimal\"\n--      |    },\n--      |    \"country\":
    \"Japan\",\n--      |    \"wards\": 11\n--      }\n--\n--   An example of setting
    align_keys to true:\n--\n--     JSON:encode_pretty(data, nil, { pretty = true,
    indent = \"  \", align_keys = true })\n--  \n--   produces:\n--   \n--      {\n--
    \          \"city\": \"Kyoto\",\n--        \"climate\": {\n--                     \"avg_temp\":
    16,\n--                     \"humidity\": \"high\",\n--                     \"snowfall\":
    \"minimal\"\n--                   },\n--        \"country\": \"Japan\",\n--          \"wards\":
    11\n--      }\n--\n--   which I must admit is kinda ugly, sorry. This was the
    default for\n--   encode_pretty() prior to version 20141223.14.\n--\n--\n--  HANDLING
    UNICODE LINE AND PARAGRAPH SEPARATORS FOR JAVA\n--\n--    If the 'stringsAreUtf8'
    encode option is set to true, consider Lua strings not as a sequence of bytes,\n--
    \   but as a sequence of UTF-8 characters.\n--\n--    Currently, the only practical
    effect of setting this option is that Unicode LINE and PARAGRAPH\n--    separators,
    if found in a string, are encoded with a JSON escape instead of being dumped as
    is.\n--    The JSON is valid either way, but encoding this way, apparently, allows
    the resulting JSON\n--    to also be valid Java.\n--\n--  AMBIGUOUS SITUATIONS
    DURING THE ENCODING\n--\n--   During the encode, if a Lua table being encoded
    contains both string\n--   and numeric keys, it fits neither JSON's idea of an
    object, nor its\n--   idea of an array. To get around this, when any string key
    exists (or\n--   when non-positive numeric keys exist), numeric keys are converted
    to\n--   strings.\n--\n--   For example, \n--     JSON:encode({ \"one\", \"two\",
    \"three\", SOMESTRING = \"some string\" }))\n--   produces the JSON object\n--
    \    {\"1\":\"one\",\"2\":\"two\",\"3\":\"three\",\"SOMESTRING\":\"some string\"}\n--\n--
    \  To prohibit this conversion and instead make it an error condition, set\n--
    \     JSON.noKeyConversion = true\n--\n--\n-- ENCODING JSON NULL VALUES\n--\n--
    \  Lua tables completely omit keys whose value is nil, so without special handling
    there's\n--   no way to represent JSON object's null value in a Lua table.  For
    example\n--      JSON:encode({ username = \"admin\", password = nil })\n--\n--
    \  produces:\n--\n--      {\"username\":\"admin\"}\n--\n--   In order to actually
    produce\n--\n--      {\"username\":\"admin\", \"password\":null}\n--\n\n--   one
    can include a string value for a \"null\" field in the options table passed to
    encode().... \n--   any Lua table entry with that value becomes null in the JSON
    output:\n--\n--      JSON:encode({ username = \"admin\", password = \"xyzzy\"
    }, -- First arg is the Lua table to encode as JSON.\n--                  nil,
    \                                       -- Second arg is the 'etc' value, ignored
    here\n--                  { null = \"xyzzy\" })                         -- Third
    arg is th options table\n--\n--   produces:\n--\n--      {\"username\":\"admin\",
    \"password\":null}\n--\n--   Just be sure to use a string that is otherwise unlikely
    to appear in your data.\n--   The string \"\\0\" (a string with one null byte)
    may well be appropriate for many applications.\n--\n--   The \"null\" options
    also applies to Lua tables that become JSON arrays.\n--      JSON:encode({ \"one\",
    \"two\", nil, nil })\n--\n--   produces\n--\n--      [\"one\",\"two\"]\n--\n--
    \  while\n--\n--      NullPlaceholder = \"\\0\"\n--      encode_options = { null
    = NullPlaceholder }\n--      JSON:encode({ \"one\", \"two\", NullPlaceholder,
    NullPlaceholder}, nil, encode_options)\n--   produces\n--\n--      [\"one\",\"two\",null,null]\n--\n--\n--\n--
    HANDLING LARGE AND/OR PRECISE NUMBERS\n--\n--\n--   Without special handling,
    numbers in JSON can lose precision in Lua.\n--   For example:\n--   \n--      T
    = JSON:decode('{  \"small\":12345, \"big\":12345678901234567890123456789, \"precise\":9876.67890123456789012345
    \ }')\n--\n--      print(\"small:   \",  type(T.small),    T.small)\n--      print(\"big:
    \    \",  type(T.big),      T.big)\n--      print(\"precise: \",  type(T.precise),
    \ T.precise)\n--   \n--   produces\n--   \n--      small:          number  12345\n--
    \     big:            number  1.2345678901235e+28\n--      precise:        number
    \ 9876.6789012346\n--\n--   Precision is lost with both 'big' and 'precise'.\n--\n--
    \  This package offers ways to try to handle this better (for some definitions
    of \"better\")...\n--\n--   The most precise method is by setting the global:\n--
    \  \n--      JSON.decodeNumbersAsObjects = true\n--   \n--   When this is set,
    numeric JSON data is encoded into Lua in a form that preserves the exact\n--   JSON
    numeric presentation when re-encoded back out to JSON, or accessed in Lua as a
    string.\n--\n--   This is done by encoding the numeric data with a Lua table/metatable
    that returns\n--   the possibly-imprecise numeric form when accessed numerically,
    but the original precise\n--   representation when accessed as a string.\n--\n--
    \  Consider the example above, with this option turned on:\n--\n--      JSON.decodeNumbersAsObjects
    = true\n--      \n--      T = JSON:decode('{  \"small\":12345, \"big\":12345678901234567890123456789,
    \"precise\":9876.67890123456789012345  }')\n--\n--      print(\"small:   \",  type(T.small),
    \   T.small)\n--      print(\"big:     \",  type(T.big),      T.big)\n--      print(\"precise:
    \",  type(T.precise),  T.precise)\n--   \n--   This now produces:\n--   \n--      small:
    \         table   12345\n--      big:            table   12345678901234567890123456789\n--
    \     precise:        table   9876.67890123456789012345\n--   \n--   However,
    within Lua you can still use the values (e.g. T.precise in the example above)
    in numeric\n--   contexts. In such cases you'll get the possibly-imprecise numeric
    version, but in string contexts\n--   and when the data finds its way to this
    package's encode() function, the original full-precision\n--   representation
    is used.\n--\n--   You can force access to the string or numeric version via\n--
    \       JSON:forceString()\n--        JSON:forceNumber()\n--   For example,\n--
    \       local probably_okay = JSON:forceNumber(T.small) -- 'probably_okay' is
    a number\n--\n--   Code the inspects the JSON-turned-Lua data using type() can
    run into troubles because what used to\n--   be a number can now be a table (e.g.
    as the small/big/precise example above shows). Update these\n--   situations to
    use JSON:isNumber(item), which returns nil if the item is neither a number nor
    one\n--   of these number objects. If it is either, it returns the number itself.
    For completeness there's\n--   also JSON:isString(item).\n--\n--   If you want
    to try to avoid the hassles of this \"number as an object\" kludge for all but
    really\n--   big numbers, you can set JSON.decodeNumbersAsObjects and then also
    set one or both of\n--            JSON:decodeIntegerObjectificationLength\n--
    \           JSON:decodeDecimalObjectificationLength\n--   They refer to the length
    of the part of the number before and after a decimal point. If they are\n--   set
    and their part is at least that number of digits, objectification occurs. If both
    are set,\n--   objectification occurs when either length is met.\n--\n--   -----------------------\n--\n--
    \  Even without using the JSON.decodeNumbersAsObjects option, you can encode numbers
    in your Lua\n--   table that retain high precision upon encoding to JSON, by using
    the JSON:asNumber() function:\n--\n--      T = {\n--         imprecise =                123456789123456789.123456789123456789,\n--
    \        precise   = JSON:asNumber(\"123456789123456789.123456789123456789\")\n--
    \     }\n--\n--      print(JSON:encode_pretty(T))\n--\n--   This produces:\n--\n--
    \     { \n--         \"precise\": 123456789123456789.123456789123456789,\n--         \"imprecise\":
    1.2345678912346e+17\n--      }\n--\n--\n--   -----------------------\n--\n--   A
    different way to handle big/precise JSON numbers is to have decode() merely return
    the exact\n--   string representation of the number instead of the number itself.
    This approach might be useful\n--   when the numbers are merely some kind of opaque
    object identifier and you want to work with them\n--   in Lua as strings anyway.\n--
    \  \n--   This approach is enabled by setting\n--\n--      JSON.decodeIntegerStringificationLength
    = 10\n--\n--   The value is the number of digits (of the integer part of the number)
    at which to stringify numbers.\n--   NOTE: this setting is ignored if JSON.decodeNumbersAsObjects
    is true, as that takes precedence.\n--\n--   Consider our previous example with
    this option set to 10:\n--\n--      JSON.decodeIntegerStringificationLength =
    10\n--      \n--      T = JSON:decode('{  \"small\":12345, \"big\":12345678901234567890123456789,
    \"precise\":9876.67890123456789012345  }')\n--\n--      print(\"small:   \",  type(T.small),
    \   T.small)\n--      print(\"big:     \",  type(T.big),      T.big)\n--      print(\"precise:
    \",  type(T.precise),  T.precise)\n--\n--   This produces:\n--\n--      small:
    \         number  12345\n--      big:            string  12345678901234567890123456789\n--
    \     precise:        number  9876.6789012346\n--\n--   The long integer of the
    'big' field is at least JSON.decodeIntegerStringificationLength digits\n--   in
    length, so it's converted not to a Lua integer but to a Lua string. Using a value
    of 0 or 1 ensures\n--   that all JSON numeric data becomes strings in Lua.\n--\n--
    \  Note that unlike\n--      JSON.decodeNumbersAsObjects = true\n--   this stringification
    is simple and unintelligent: the JSON number simply becomes a Lua string, and
    that's the end of it.\n--   If the string is then converted back to JSON, it's
    still a string. After running the code above, adding\n--      print(JSON:encode(T))\n--
    \  produces\n--      {\"big\":\"12345678901234567890123456789\",\"precise\":9876.6789012346,\"small\":12345}\n--
    \  which is unlikely to be desired.\n--\n--   There's a comparable option for
    the length of the decimal part of a number:\n--\n--      JSON.decodeDecimalStringificationLength\n--\n--
    \  This can be used alone or in conjunction with\n--\n--      JSON.decodeIntegerStringificationLength\n--\n--
    \  to trip stringification on precise numbers with at least JSON.decodeIntegerStringificationLength
    digits after\n--   the decimal point. (Both are ignored if JSON.decodeNumbersAsObjects
    is true.)\n--\n--   This example:\n--\n--      JSON.decodeIntegerStringificationLength
    = 10\n--      JSON.decodeDecimalStringificationLength =  5\n--\n--      T = JSON:decode('{
    \ \"small\":12345, \"big\":12345678901234567890123456789, \"precise\":9876.67890123456789012345
    \ }')\n--      \n--      print(\"small:   \",  type(T.small),    T.small)\n--
    \     print(\"big:     \",  type(T.big),      T.big)\n--      print(\"precise:
    \",  type(T.precise),  T.precise)\n--\n--  produces:\n--\n--      small:          number
    \ 12345\n--      big:            string  12345678901234567890123456789\n--      precise:
    \       string  9876.67890123456789012345\n--\n--\n--  HANDLING UNSUPPORTED VALUE
    TYPES\n--\n--   Among the encoding errors that might be raised is an attempt to
    convert a table value that has a type\n--   that this package hasn't accounted
    for: a function, userdata, or a thread. You can handle these types as table\n--
    \  values (but not as table keys) if you supply a JSON:unsupportedTypeEncoder()
    method along the lines of the\n--   following example:\n--        \n--        function
    JSON:unsupportedTypeEncoder(value_of_unsupported_type)\n--           if type(value_of_unsupported_type)
    == 'function' then\n--              return \"a function value\"\n--           else\n--
    \             return nil\n--           end\n--        end\n--        \n--   Your
    unsupportedTypeEncoder() method is actually called with a bunch of arguments:\n--\n--
    \     self:unsupportedTypeEncoder(value, parents, etc, options, indent, for_key)\n--\n--
    \  The 'value' is the function, thread, or userdata to be converted to JSON.\n--\n--
    \  The 'etc' and 'options' arguments are those passed to the original encode().
    The other arguments are\n--   probably of little interest; see the source code.
    (Note that 'for_key' is never true, as this function\n--   is invoked only on
    table values; table keys of these types still trigger the onEncodeError method.)\n--\n--
    \  If your unsupportedTypeEncoder() method returns a string, it's inserted into
    the JSON as is.\n--   If it returns nil plus an error message, that error message
    is passed through to an onEncodeError invocation.\n--   If it returns only nil,
    processing falls through to a default onEncodeError invocation.\n--\n--   If you
    want to handle everything in a simple way:\n--\n--        function JSON:unsupportedTypeEncoder(value)\n--
    \          return tostring(value)\n--        end\n--\n--\n-- SUMMARY OF METHODS
    YOU CAN OVERRIDE IN YOUR LOCAL LUA JSON OBJECT\n--\n--    assert\n--    onDecodeError\n--
    \   onDecodeOfNilError\n--    onDecodeOfHTMLError\n--    onTrailingGarbage\n--
    \   onEncodeError\n--    unsupportedTypeEncoder\n--\n--  If you want to create
    a separate Lua JSON object with its own error handlers,\n--  you can reload JSON.lua
    or use the :new() method.\n--\n---------------------------------------------------------------------------\n\nlocal
    default_pretty_indent  = \"  \"\nlocal default_pretty_options = { pretty = true,
    indent = default_pretty_indent, align_keys = false, array_newline = false }\n\nlocal
    isArray  = { __tostring = function() return \"JSON array\"         end }  isArray.__index
    \ = isArray\nlocal isObject = { __tostring = function() return \"JSON object\"
    \       end }  isObject.__index = isObject\n\nfunction OBJDEF:newArray(tbl)\n
    \  return setmetatable(tbl or {}, isArray)\nend\n\nfunction OBJDEF:newObject(tbl)\n
    \  return setmetatable(tbl or {}, isObject)\nend\n\n\n\n\nlocal function getnum(op)\n
    \  return type(op) == 'number' and op or op.N\nend\n\nlocal isNumber = {\n   __tostring
    = function(T)  return T.S        end,\n   __unm      = function(op) return getnum(op)
    end,\n\n   __concat   = function(op1, op2) return tostring(op1) .. tostring(op2)
    end,\n   __add      = function(op1, op2) return getnum(op1)   +   getnum(op2)
    \ end,\n   __sub      = function(op1, op2) return getnum(op1)   -   getnum(op2)
    \ end,\n   __mul      = function(op1, op2) return getnum(op1)   *   getnum(op2)
    \ end,\n   __div      = function(op1, op2) return getnum(op1)   /   getnum(op2)
    \ end,\n   __mod      = function(op1, op2) return getnum(op1)   %   getnum(op2)
    \ end,\n   __pow      = function(op1, op2) return getnum(op1)   ^   getnum(op2)
    \ end,\n   __lt       = function(op1, op2) return getnum(op1)   <   getnum(op2)
    \ end,\n   __eq       = function(op1, op2) return getnum(op1)   ==  getnum(op2)
    \ end,\n   __le       = function(op1, op2) return getnum(op1)   <=  getnum(op2)
    \ end,\n}\nisNumber.__index = isNumber\n\nfunction OBJDEF:asNumber(item)\n\n   if
    getmetatable(item) == isNumber then\n      -- it's already a JSON number object.\n
    \     return item\n   elseif type(item) == 'table' and type(item.S) == 'string'
    and type(item.N) == 'number' then\n      -- it's a number-object table that lost
    its metatable, so give it one\n      return setmetatable(item, isNumber)\n   else\n
    \     -- the normal situation... given a number or a string representation of
    a number....\n      local holder = {\n         S = tostring(item), -- S is the
    representation of the number as a string, which remains precise\n         N =
    tonumber(item), -- N is the number as a Lua number.\n      }\n      return setmetatable(holder,
    isNumber)\n   end\nend\n\n--\n-- Given an item that might be a normal string or
    number, or might be an 'isNumber' object defined above,\n-- return the string
    version. This shouldn't be needed often because the 'isNumber' object should autoconvert\n--
    to a string in most cases, but it's here to allow it to be forced when needed.\n--\nfunction
    OBJDEF:forceString(item)\n   if type(item) == 'table' and type(item.S) == 'string'
    then\n      return item.S\n   else\n      return tostring(item)\n   end\nend\n\n--\n--
    Given an item that might be a normal string or number, or might be an 'isNumber'
    object defined above,\n-- return the numeric version.\n--\nfunction OBJDEF:forceNumber(item)\n
    \  if type(item) == 'table' and type(item.N) == 'number' then\n      return item.N\n
    \  else\n      return tonumber(item)\n   end\nend\n\n--\n-- If the given item
    is a number, return it. Otherwise, return nil.\n-- This, this can be used both
    in a conditional and to access the number when you're not sure its form.\n--\nfunction
    OBJDEF:isNumber(item)\n   if type(item) == 'number' then\n      return item\n
    \  elseif type(item) == 'table' and type(item.N) == 'number' then\n      return
    item.N\n   else\n      return nil\n   end\nend\n\nfunction OBJDEF:isString(item)\n
    \  if type(item) == 'string' then\n      return item\n   elseif type(item) ==
    'table' and type(item.S) == 'string' then\n      return item.S\n   else\n      return
    nil\n   end\nend\n\n\nlocal function unicode_codepoint_as_utf8(codepoint)\n   --\n
    \  -- codepoint is a number\n   --\n   if codepoint <= 127 then\n      return
    string.char(codepoint)\n\n   elseif codepoint <= 2047 then\n      --\n      --
    110yyyxx 10xxxxxx         <-- useful notation from http://en.wikipedia.org/wiki/Utf8\n
    \     --\n      local highpart = math.floor(codepoint / 0x40)\n      local lowpart
    \ = codepoint - (0x40 * highpart)\n      return string.char(0xC0 + highpart,\n
    \                        0x80 + lowpart)\n\n   elseif codepoint <= 65535 then\n
    \     --\n      -- 1110yyyy 10yyyyxx 10xxxxxx\n      --\n      local highpart
    \ = math.floor(codepoint / 0x1000)\n      local remainder = codepoint - 0x1000
    * highpart\n      local midpart   = math.floor(remainder / 0x40)\n      local
    lowpart   = remainder - 0x40 * midpart\n\n      highpart = 0xE0 + highpart\n      midpart
    \ = 0x80 + midpart\n      lowpart  = 0x80 + lowpart\n\n      --\n      -- Check
    for an invalid character (thanks Andy R. at Adobe).\n      -- See table 3.7, page
    93, in http://www.unicode.org/versions/Unicode5.2.0/ch03.pdf#G28070\n      --\n
    \     if ( highpart == 0xE0 and midpart < 0xA0 ) or\n         ( highpart == 0xED
    and midpart > 0x9F ) or\n         ( highpart == 0xF0 and midpart < 0x90 ) or\n
    \        ( highpart == 0xF4 and midpart > 0x8F )\n      then\n         return
    \"?\"\n      else\n         return string.char(highpart,\n                            midpart,\n
    \                           lowpart)\n      end\n\n   else\n      --\n      --
    11110zzz 10zzyyyy 10yyyyxx 10xxxxxx\n      --\n      local highpart  = math.floor(codepoint
    / 0x40000)\n      local remainder = codepoint - 0x40000 * highpart\n      local
    midA      = math.floor(remainder / 0x1000)\n      remainder       = remainder
    - 0x1000 * midA\n      local midB      = math.floor(remainder / 0x40)\n      local
    lowpart   = remainder - 0x40 * midB\n\n      return string.char(0xF0 + highpart,\n
    \                        0x80 + midA,\n                         0x80 + midB,\n
    \                        0x80 + lowpart)\n   end\nend\n\nfunction OBJDEF:onDecodeError(message,
    text, location, etc)\n   if text then\n      if location then\n         message
    = string.format(\"%s at byte %d of: %s\", message, location, text)\n      else\n
    \        message = string.format(\"%s: %s\", message, text)\n      end\n   end\n\n
    \  if etc ~= nil then\n      message = message .. \" (\" .. OBJDEF:encode(etc)
    .. \")\"\n   end\n\n   if self.assert then\n      self.assert(false, message)\n
    \  else\n      assert(false, message)\n   end\nend\n\nfunction OBJDEF:onTrailingGarbage(json_text,
    location, parsed_value, etc)\n   return self:onDecodeError(\"trailing garbage\",
    json_text, location, etc)\nend\n\nOBJDEF.onDecodeOfNilError  = OBJDEF.onDecodeError\nOBJDEF.onDecodeOfHTMLError
    = OBJDEF.onDecodeError\n\nfunction OBJDEF:onEncodeError(message, etc)\n   if etc
    ~= nil then\n      message = message .. \" (\" .. OBJDEF:encode(etc) .. \")\"\n
    \  end\n\n   if self.assert then\n      self.assert(false, message)\n   else\n
    \     assert(false, message)\n   end\nend\n\nlocal function grok_number(self,
    text, start, options)\n   --\n   -- Grab the integer part\n   --\n   local integer_part
    = text:match('^-?[1-9]%d*', start)\n                     or text:match(\"^-?0\",
    \       start)\n\n   if not integer_part then\n      self:onDecodeError(\"expected
    number\", text, start, options.etc)\n      return nil, start -- in case the error
    method doesn't abort, return something sensible\n   end\n\n   local i = start
    + integer_part:len()\n\n   --\n   -- Grab an optional decimal part\n   --\n   local
    decimal_part = text:match('^%.%d+', i) or \"\"\n\n   i = i + decimal_part:len()\n\n
    \  --\n   -- Grab an optional exponential part\n   --\n   local exponent_part
    = text:match('^[eE][-+]?%d+', i) or \"\"\n\n   i = i + exponent_part:len()\n\n
    \  local full_number_text = integer_part .. decimal_part .. exponent_part\n\n
    \  if options.decodeNumbersAsObjects then\n\n      local objectify = false\n\n
    \     if not options.decodeIntegerObjectificationLength and not options.decodeDecimalObjectificationLength
    then\n         -- no options, so objectify\n         objectify = true\n\n      elseif
    (options.decodeIntegerObjectificationLength\n          and\n         (integer_part:len()
    >= options.decodeIntegerObjectificationLength or exponent_part:len() > 0))\n\n
    \         or\n         (options.decodeDecimalObjectificationLength \n          and\n
    \         (decimal_part:len() >= options.decodeDecimalObjectificationLength  or
    exponent_part:len() > 0))\n      then\n         -- have options and they are triggered,
    so objectify\n         objectify = true\n      end\n\n      if objectify then\n
    \        return OBJDEF:asNumber(full_number_text), i\n      end\n      -- else,
    fall through to try to return as a straight-up number\n\n   else\n\n      -- Not
    always decoding numbers as objects, so perhaps encode as strings?\n\n      --\n
    \     -- If we're told to stringify only under certain conditions, so do.\n      --
    We punt a bit when there's an exponent by just stringifying no matter what.\n
    \     -- I suppose we should really look to see whether the exponent is actually
    big enough one\n      -- way or the other to trip stringification, but I'll be
    lazy about it until someone asks.\n      --\n      if (options.decodeIntegerStringificationLength\n
    \         and\n         (integer_part:len() >= options.decodeIntegerStringificationLength
    or exponent_part:len() > 0))\n\n          or\n\n         (options.decodeDecimalStringificationLength
    \n          and\n          (decimal_part:len() >= options.decodeDecimalStringificationLength
    or exponent_part:len() > 0))\n      then\n         return full_number_text, i
    -- this returns the exact string representation seen in the original JSON\n      end\n\n
    \  end\n\n\n   local as_number = tonumber(full_number_text)\n\n   if not as_number
    then\n      self:onDecodeError(\"bad number\", text, start, options.etc)\n      return
    nil, start -- in case the error method doesn't abort, return something sensible\n
    \  end\n\n   return as_number, i\nend\n\n\nlocal function grok_string(self, text,
    start, options)\n\n   if text:sub(start,start) ~= '\"' then\n      self:onDecodeError(\"expected
    string's opening quote\", text, start, options.etc)\n      return nil, start --
    in case the error method doesn't abort, return something sensible\n   end\n\n
    \  local i = start + 1 -- +1 to bypass the initial quote\n   local text_len =
    text:len()\n   local VALUE = \"\"\n   while i <= text_len do\n      local c =
    text:sub(i,i)\n      if c == '\"' then\n         return VALUE, i + 1\n      end\n
    \     if c ~= '\\\\' then\n         VALUE = VALUE .. c\n         i = i + 1\n      elseif
    text:match('^\\\\b', i) then\n         VALUE = VALUE .. \"\\b\"\n         i =
    i + 2\n      elseif text:match('^\\\\f', i) then\n         VALUE = VALUE .. \"\\f\"\n
    \        i = i + 2\n      elseif text:match('^\\\\n', i) then\n         VALUE
    = VALUE .. \"\\n\"\n         i = i + 2\n      elseif text:match('^\\\\r', i) then\n
    \        VALUE = VALUE .. \"\\r\"\n         i = i + 2\n      elseif text:match('^\\\\t',
    i) then\n         VALUE = VALUE .. \"\\t\"\n         i = i + 2\n      else\n         local
    hex = text:match('^\\\\u([0123456789aAbBcCdDeEfF][0123456789aAbBcCdDeEfF][0123456789aAbBcCdDeEfF][0123456789aAbBcCdDeEfF])',
    i)\n         if hex then\n            i = i + 6 -- bypass what we just read\n\n
    \           -- We have a Unicode codepoint. It could be standalone, or if in the
    proper range and\n            -- followed by another in a specific range, it'll
    be a two-code surrogate pair.\n            local codepoint = tonumber(hex, 16)\n
    \           if codepoint >= 0xD800 and codepoint <= 0xDBFF then\n               --
    it's a hi surrogate... see whether we have a following low\n               local
    lo_surrogate = text:match('^\\\\u([dD][cdefCDEF][0123456789aAbBcCdDeEfF][0123456789aAbBcCdDeEfF])',
    i)\n               if lo_surrogate then\n                  i = i + 6 -- bypass
    the low surrogate we just read\n                  codepoint = 0x2400 + (codepoint
    - 0xD800) * 0x400 + tonumber(lo_surrogate, 16)\n               else\n                  --
    not a proper low, so we'll just leave the first codepoint as is and spit it out.\n
    \              end\n            end\n            VALUE = VALUE .. unicode_codepoint_as_utf8(codepoint)\n\n
    \        else\n\n            -- just pass through what's escaped\n            VALUE
    = VALUE .. text:match('^\\\\(.)', i)\n            i = i + 2\n         end\n      end\n
    \  end\n\n   self:onDecodeError(\"unclosed string\", text, start, options.etc)\n
    \  return nil, start -- in case the error method doesn't abort, return something
    sensible\nend\n\nlocal function skip_whitespace(text, start)\n\n   local _, match_end
    = text:find(\"^[ \\n\\r\\t]+\", start) -- [http://www.ietf.org/rfc/rfc4627.txt]
    Section 2\n   if match_end then\n      return match_end + 1\n   else\n      return
    start\n   end\nend\n\nlocal grok_one -- assigned later\n\nlocal function grok_object(self,
    text, start, options)\n\n   if text:sub(start,start) ~= '{' then\n      self:onDecodeError(\"expected
    '{'\", text, start, options.etc)\n      return nil, start -- in case the error
    method doesn't abort, return something sensible\n   end\n\n   local i = skip_whitespace(text,
    start + 1) -- +1 to skip the '{'\n\n   local VALUE = self.strictTypes and self:newObject
    { } or { }\n\n   if text:sub(i,i) == '}' then\n      return VALUE, i + 1\n   end\n
    \  local text_len = text:len()\n   while i <= text_len do\n      local key, new_i
    = grok_string(self, text, i, options)\n\n      i = skip_whitespace(text, new_i)\n\n
    \     if text:sub(i, i) ~= ':' then\n         self:onDecodeError(\"expected colon\",
    text, i, options.etc)\n         return nil, i -- in case the error method doesn't
    abort, return something sensible\n      end\n\n      i = skip_whitespace(text,
    i + 1)\n\n      local new_val, new_i = grok_one(self, text, i, options)\n\n      VALUE[key]
    = new_val\n\n      --\n      -- Expect now either '}' to end things, or a ','
    to allow us to continue.\n      --\n      i = skip_whitespace(text, new_i)\n\n
    \     local c = text:sub(i,i)\n\n      if c == '}' then\n         return VALUE,
    i + 1\n      end\n\n      if text:sub(i, i) ~= ',' then\n         self:onDecodeError(\"expected
    comma or '}'\", text, i, options.etc)\n         return nil, i -- in case the error
    method doesn't abort, return something sensible\n      end\n\n      i = skip_whitespace(text,
    i + 1)\n   end\n\n   self:onDecodeError(\"unclosed '{'\", text, start, options.etc)\n
    \  return nil, start -- in case the error method doesn't abort, return something
    sensible\nend\n\nlocal function grok_array(self, text, start, options)\n   if
    text:sub(start,start) ~= '[' then\n      self:onDecodeError(\"expected '['\",
    text, start, options.etc)\n      return nil, start -- in case the error method
    doesn't abort, return something sensible\n   end\n\n   local i = skip_whitespace(text,
    start + 1) -- +1 to skip the '['\n   local VALUE = self.strictTypes and self:newArray
    { } or { }\n   if text:sub(i,i) == ']' then\n      return VALUE, i + 1\n   end\n\n
    \  local VALUE_INDEX = 1\n\n   local text_len = text:len()\n   while i <= text_len
    do\n      local val, new_i = grok_one(self, text, i, options)\n\n      -- can't
    table.insert(VALUE, val) here because it's a no-op if val is nil\n      VALUE[VALUE_INDEX]
    = val\n      VALUE_INDEX = VALUE_INDEX + 1\n\n      i = skip_whitespace(text,
    new_i)\n\n      --\n      -- Expect now either ']' to end things, or a ',' to
    allow us to continue.\n      --\n      local c = text:sub(i,i)\n      if c ==
    ']' then\n         return VALUE, i + 1\n      end\n      if text:sub(i, i) ~=
    ',' then\n         self:onDecodeError(\"expected comma or ']'\", text, i, options.etc)\n
    \        return nil, i -- in case the error method doesn't abort, return something
    sensible\n      end\n      i = skip_whitespace(text, i + 1)\n   end\n   self:onDecodeError(\"unclosed
    '['\", text, start, options.etc)\n   return nil, i -- in case the error method
    doesn't abort, return something sensible\nend\n\n\ngrok_one = function(self, text,
    start, options)\n   -- Skip any whitespace\n   start = skip_whitespace(text, start)\n\n
    \  if start > text:len() then\n      self:onDecodeError(\"unexpected end of string\",
    text, nil, options.etc)\n      return nil, start -- in case the error method doesn't
    abort, return something sensible\n   end\n\n   if text:find('^\"', start) then\n
    \     return grok_string(self, text, start, options.etc)\n\n   elseif text:find('^[-0123456789
    ]', start) then\n      return grok_number(self, text, start, options)\n\n   elseif
    text:find('^%{', start) then\n      return grok_object(self, text, start, options)\n\n
    \  elseif text:find('^%[', start) then\n      return grok_array(self, text, start,
    options)\n\n   elseif text:find('^true', start) then\n      return true, start
    + 4\n\n   elseif text:find('^false', start) then\n      return false, start +
    5\n\n   elseif text:find('^null', start) then\n      return options.null, start
    + 4\n\n   else\n      self:onDecodeError(\"can't parse JSON\", text, start, options.etc)\n
    \     return nil, 1 -- in case the error method doesn't abort, return something
    sensible\n   end\nend\n\nfunction OBJDEF:decode(text, etc, options)\n   --\n   --
    If the user didn't pass in a table of decode options, make an empty one.\n   --\n
    \  if type(options) ~= 'table' then\n      options = {}\n   end\n\n   --\n   --
    If they passed in an 'etc' argument, stuff it into the options.\n   -- (If not,
    any 'etc' field in the options they passed in remains to be used)\n   --\n   if
    etc ~= nil then\n      options.etc = etc\n   end\n\n\n   if type(self) ~= 'table'
    or self.__index ~= OBJDEF then\n      local error_message = \"JSON:decode must
    be called in method format\"\n      OBJDEF:onDecodeError(error_message, nil, nil,
    options.etc)\n      return nil, error_message -- in case the error method doesn't
    abort, return something sensible\n   end\n\n   if text == nil then\n      local
    error_message = \"nil passed to JSON:decode()\"\n      self:onDecodeOfNilError(error_message,
    nil, nil, options.etc)\n      return nil, error_message -- in case the error method
    doesn't abort, return something sensible\n\n   elseif type(text) ~= 'string' then\n
    \     local error_message = \"expected string argument to JSON:decode()\"\n      self:onDecodeError(string.format(\"%s,
    got %s\", error_message, type(text)), nil, nil, options.etc)\n      return nil,
    error_message -- in case the error method doesn't abort, return something sensible\n
    \  end\n\n   if text:match('^%s*$') then\n      -- an empty string is nothing,
    but not an error\n      return nil\n   end\n\n   if text:match('^%s*<') then\n
    \     -- Can't be JSON... we'll assume it's HTML\n      local error_message =
    \"HTML passed to JSON:decode()\"\n      self:onDecodeOfHTMLError(error_message,
    text, nil, options.etc)\n      return nil, error_message -- in case the error
    method doesn't abort, return something sensible\n   end\n\n   --\n   -- Ensure
    that it's not UTF-32 or UTF-16.\n   -- Those are perfectly valid encodings for
    JSON (as per RFC 4627 section 3),\n   -- but this package can't handle them.\n
    \  --\n   if text:sub(1,1):byte() == 0 or (text:len() >= 2 and text:sub(2,2):byte()
    == 0) then\n      local error_message = \"JSON package groks only UTF-8, sorry\"\n
    \     self:onDecodeError(error_message, text, nil, options.etc)\n      return
    nil, error_message -- in case the error method doesn't abort, return something
    sensible\n   end\n\n   --\n   -- apply global options\n   --\n   if options.decodeNumbersAsObjects
    == nil then\n      options.decodeNumbersAsObjects = self.decodeNumbersAsObjects\n
    \  end\n   if options.decodeIntegerObjectificationLength == nil then\n      options.decodeIntegerObjectificationLength
    = self.decodeIntegerObjectificationLength\n   end\n   if options.decodeDecimalObjectificationLength
    == nil then\n      options.decodeDecimalObjectificationLength = self.decodeDecimalObjectificationLength\n
    \  end\n   if options.decodeIntegerStringificationLength == nil then\n      options.decodeIntegerStringificationLength
    = self.decodeIntegerStringificationLength\n   end\n   if options.decodeDecimalStringificationLength
    == nil then\n      options.decodeDecimalStringificationLength = self.decodeDecimalStringificationLength\n
    \  end\n\n\n   --\n   -- Finally, go parse it\n   --\n   local success, value,
    next_i = pcall(grok_one, self, text, 1, options)\n\n   if success then\n\n      local
    error_message = nil\n      if next_i ~= #text + 1 then\n         -- something's
    left over after we parsed the first thing.... whitespace is allowed.\n         next_i
    = skip_whitespace(text, next_i)\n\n         -- if we have something left over
    now, it's trailing garbage\n         if next_i ~= #text + 1 then\n            value,
    error_message = self:onTrailingGarbage(text, next_i, value, options.etc)\n         end\n
    \     end\n      return value, error_message\n\n   else\n\n      -- If JSON:onDecodeError()
    didn't abort out of the pcall, we'll have received\n      -- the error message
    here as \"value\", so pass it along as an assert.\n      local error_message =
    value\n      if self.assert then\n         self.assert(false, error_message)\n
    \     else\n         assert(false, error_message)\n      end\n      -- ...and
    if we're still here (because the assert didn't throw an error),\n      -- return
    a nil and throw the error message on as a second arg\n      return nil, error_message\n\n
    \  end\nend\n\nlocal function backslash_replacement_function(c)\n   if c == \"\\n\"
    then\n      return \"\\\\n\"\n   elseif c == \"\\r\" then\n      return \"\\\\r\"\n
    \  elseif c == \"\\t\" then\n      return \"\\\\t\"\n   elseif c == \"\\b\" then\n
    \     return \"\\\\b\"\n   elseif c == \"\\f\" then\n      return \"\\\\f\"\n
    \  elseif c == '\"' then\n      return '\\\\\"'\n   elseif c == '\\\\' then\n
    \     return '\\\\\\\\'\n   else\n      return string.format(\"\\\\u%04x\", c:byte())\n
    \  end\nend\n\nlocal chars_to_be_escaped_in_JSON_string\n   = '['\n   ..    '\"'
    \   -- class sub-pattern to match a double quote\n   ..    '%\\\\'  -- class sub-pattern
    to match a backslash\n   ..    '%z'   -- class sub-pattern to match a null\n   ..
    \   '\\001' .. '-' .. '\\031' -- class sub-pattern to match control characters\n
    \  .. ']'\n\n\nlocal LINE_SEPARATOR_as_utf8      = unicode_codepoint_as_utf8(0x2028)\nlocal
    PARAGRAPH_SEPARATOR_as_utf8 = unicode_codepoint_as_utf8(0x2029)\nlocal function
    json_string_literal(value, options)\n   local newval = value:gsub(chars_to_be_escaped_in_JSON_string,
    backslash_replacement_function)\n   if options.stringsAreUtf8 then\n      --\n
    \     -- This feels really ugly to just look into a string for the sequence of
    bytes that we know to be a particular utf8 character,\n      -- but utf8 was designed
    purposefully to make this kind of thing possible. Still, feels dirty.\n      --
    I'd rather decode the byte stream into a character stream, but it's not technically
    needed so\n      -- not technically worth it.\n      --\n      newval = newval:gsub(LINE_SEPARATOR_as_utf8,
    '\\\\u2028'):gsub(PARAGRAPH_SEPARATOR_as_utf8,'\\\\u2029')\n   end\n   return
    '\"' .. newval .. '\"'\nend\n\nlocal function object_or_array(self, T, etc)\n
    \  --\n   -- We need to inspect all the keys... if there are any strings, we'll
    convert to a JSON\n   -- object. If there are only numbers, it's a JSON array.\n
    \  --\n   -- If we'll be converting to a JSON object, we'll want to sort the keys
    so that the\n   -- end result is deterministic.\n   --\n   local string_keys =
    { }\n   local number_keys = { }\n   local number_keys_must_be_strings = false\n
    \  local maximum_number_key\n\n   for key in pairs(T) do\n      if type(key) ==
    'string' then\n         table.insert(string_keys, key)\n      elseif type(key)
    == 'number' then\n         table.insert(number_keys, key)\n         if key <=
    0 or key >= math.huge then\n            number_keys_must_be_strings = true\n         elseif
    not maximum_number_key or key > maximum_number_key then\n            maximum_number_key
    = key\n         end\n      elseif type(key) == 'boolean' then\n         table.insert(string_keys,
    tostring(key))\n      else\n         self:onEncodeError(\"can't encode table with
    a key of type \" .. type(key), etc)\n      end\n   end\n\n   if #string_keys ==
    0 and not number_keys_must_be_strings then\n      --\n      -- An empty table,
    or a numeric-only array\n      --\n      if #number_keys > 0 then\n         return
    nil, maximum_number_key -- an array\n      elseif tostring(T) == \"JSON array\"
    then\n         return nil\n      elseif tostring(T) == \"JSON object\" then\n
    \        return { }\n      else\n         -- have to guess, so we'll pick array,
    since empty arrays are likely more common than empty objects\n         return
    nil\n      end\n   end\n\n   table.sort(string_keys)\n\n   local map\n   if #number_keys
    > 0 then\n      --\n      -- If we're here then we have either mixed string/number
    keys, or numbers inappropriate for a JSON array\n      -- It's not ideal, but
    we'll turn the numbers into strings so that we can at least create a JSON object.\n
    \     --\n\n      if self.noKeyConversion then\n         self:onEncodeError(\"a
    table with both numeric and string keys could be an object or array; aborting\",
    etc)\n      end\n\n      --\n      -- Have to make a shallow copy of the source
    table so we can remap the numeric keys to be strings\n      --\n      map = {
    }\n      for key, val in pairs(T) do\n         map[key] = val\n      end\n\n      table.sort(number_keys)\n\n
    \     --\n      -- Throw numeric keys in there as strings\n      --\n      for
    _, number_key in ipairs(number_keys) do\n         local string_key = tostring(number_key)\n
    \        if map[string_key] == nil then\n            table.insert(string_keys
    , string_key)\n            map[string_key] = T[number_key]\n         else\n            self:onEncodeError(\"conflict
    converting table with mixed-type keys into a JSON object: key \" .. number_key
    .. \" exists both as a string and a number.\", etc)\n         end\n      end\n
    \  end\n\n   return string_keys, nil, map\nend\n\n--\n-- Encode\n--\n-- 'options'
    is nil, or a table with possible keys:\n--\n--    pretty         -- If true, return
    a pretty-printed version.\n--\n--    indent         -- A string (usually of spaces)
    used to indent each nested level.\n--\n--    align_keys     -- If true, align
    all the keys when formatting a table. The result is uglier than one might at first
    imagine.\n--                      Results are undefined if 'align_keys' is true
    but 'pretty' is not.\n--\n--    array_newline  -- If true, array elements are
    formatted each to their own line. The default is to all fall inline.\n--                      Results
    are undefined if 'array_newline' is true but 'pretty' is not.\n--\n--    null
    \          -- If this exists with a string value, table elements with this value
    are output as JSON null.\n--\n--    stringsAreUtf8 -- If true, consider Lua strings
    not as a sequence of bytes, but as a sequence of UTF-8 characters.\n--                      (Currently,
    the only practical effect of setting this option is that Unicode LINE and PARAGRAPH\n--
    \                      separators, if found in a string, are encoded with a JSON
    escape instead of as raw UTF-8.\n--                       The JSON is valid either
    way, but encoding this way, apparently, allows the resulting JSON\n--                       to
    also be valid Java.)\n--\n--\nlocal function encode_value(self, value, parents,
    etc, options, indent, for_key)\n\n   --\n   -- keys in a JSON object can never
    be null, so we don't even consider options.null when converting a key value\n
    \  --\n   if value == nil or (not for_key and options and options.null and value
    == options.null) then\n      return 'null'\n\n   elseif type(value) == 'string'
    then\n      return json_string_literal(value, options)\n\n   elseif type(value)
    == 'number' then\n      if value ~= value then\n         --\n         -- NaN (Not
    a Number).\n         -- JSON has no NaN, so we have to fudge the best we can.
    This should really be a package option.\n         --\n         return \"null\"\n
    \     elseif value >= math.huge then\n         --\n         -- Positive infinity.
    JSON has no INF, so we have to fudge the best we can. This should\n         --
    really be a package option. Note: at least with some implementations, positive
    infinity\n         -- is both \">= math.huge\" and \"<= -math.huge\", which makes
    no sense but that's how it is.\n         -- Negative infinity is properly \"<=
    -math.huge\". So, we must be sure to check the \">=\"\n         -- case first.\n
    \        --\n         return \"1e+9999\"\n      elseif value <= -math.huge then\n
    \        --\n         -- Negative infinity.\n         -- JSON has no INF, so we
    have to fudge the best we can. This should really be a package option.\n         --\n
    \        return \"-1e+9999\"\n      else\n         return tostring(value)\n      end\n\n
    \  elseif type(value) == 'boolean' then\n      return tostring(value)\n\n   elseif
    type(value) ~= 'table' then\n\n      if self.unsupportedTypeEncoder then\n         local
    user_value, user_error = self:unsupportedTypeEncoder(value, parents, etc, options,
    indent, for_key)\n         -- If the user's handler returns a string, use that.
    If it returns nil plus an error message, bail with that.\n         -- If only
    nil returned, fall through to the default error handler.\n         if type(user_value)
    == 'string' then\n            return user_value\n         elseif user_value ~=
    nil then\n            self:onEncodeError(\"unsupportedTypeEncoder method returned
    a \" .. type(user_value), etc)\n         elseif user_error then\n            self:onEncodeError(tostring(user_error),
    etc)\n         end\n      end\n\n      self:onEncodeError(\"can't convert \" ..
    type(value) .. \" to JSON\", etc)\n\n   elseif getmetatable(value) == isNumber
    then\n      return tostring(value)\n   else\n      --\n      -- A table to be
    converted to either a JSON object or array.\n      --\n      local T = value\n\n
    \     if type(options) ~= 'table' then\n         options = {}\n      end\n      if
    type(indent) ~= 'string' then\n         indent = \"\"\n      end\n\n      if parents[T]
    then\n         self:onEncodeError(\"table \" .. tostring(T) .. \" is a child of
    itself\", etc)\n      else\n         parents[T] = true\n      end\n\n      local
    result_value\n\n      local object_keys, maximum_number_key, map = object_or_array(self,
    T, etc)\n      if maximum_number_key then\n         --\n         -- An array...\n
    \        --\n         local key_indent\n         if options.array_newline then\n
    \           key_indent = indent .. tostring(options.indent or \"\")\n         else\n
    \           key_indent = indent\n         end\n\n         local ITEMS = { }\n
    \        for i = 1, maximum_number_key do\n            table.insert(ITEMS, encode_value(self,
    T[i], parents, etc, options, key_indent))\n         end\n\n         if options.array_newline
    then\n            result_value = \"[\\n\" .. key_indent .. table.concat(ITEMS,
    \",\\n\" .. key_indent) .. \"\\n\" .. indent .. \"]\"\n         elseif options.pretty
    then\n            result_value = \"[ \" .. table.concat(ITEMS, \", \") .. \" ]\"\n
    \        else\n            result_value = \"[\"  .. table.concat(ITEMS, \",\")
    \ .. \"]\"\n         end\n\n      elseif object_keys then\n         --\n         --
    An object\n         --\n         local TT = map or T\n\n         if options.pretty
    then\n\n            local KEYS = { }\n            local max_key_length = 0\n            for
    _, key in ipairs(object_keys) do\n               local encoded = encode_value(self,
    tostring(key), parents, etc, options, indent, true)\n               if options.align_keys
    then\n                  max_key_length = math.max(max_key_length, #encoded)\n
    \              end\n               table.insert(KEYS, encoded)\n            end\n
    \           local key_indent = indent .. tostring(options.indent or \"\")\n            local
    subtable_indent = key_indent .. string.rep(\" \", max_key_length) .. (options.align_keys
    and \"  \" or \"\")\n            local FORMAT = \"%s%\" .. string.format(\"%d\",
    max_key_length) .. \"s: %s\"\n\n            local COMBINED_PARTS = { }\n            for
    i, key in ipairs(object_keys) do\n               local encoded_val = encode_value(self,
    TT[key], parents, etc, options, subtable_indent)\n               table.insert(COMBINED_PARTS,
    string.format(FORMAT, key_indent, KEYS[i], encoded_val))\n            end\n            result_value
    = \"{\\n\" .. table.concat(COMBINED_PARTS, \",\\n\") .. \"\\n\" .. indent .. \"}\"\n\n
    \        else\n\n            local PARTS = { }\n            for _, key in ipairs(object_keys)
    do\n               local encoded_val = encode_value(self, TT[key],       parents,
    etc, options, indent)\n               local encoded_key = encode_value(self, tostring(key),
    parents, etc, options, indent, true)\n               table.insert(PARTS, string.format(\"%s:%s\",
    encoded_key, encoded_val))\n            end\n            result_value = \"{\"
    .. table.concat(PARTS, \",\") .. \"}\"\n\n         end\n      else\n         --\n
    \        -- An empty array/object... we'll treat it as an array, though it should
    really be an option\n         --\n         result_value = \"[]\"\n      end\n\n
    \     parents[T] = false\n      return result_value\n   end\nend\n\nlocal function
    top_level_encode(self, value, etc, options)\n   local val = encode_value(self,
    value, {}, etc, options)\n   if val == nil then\n      --PRIVATE(\"may need to
    revert to the previous public verison if I can't figure out what the guy wanted\")\n
    \     return val\n   else\n      return val\n   end\nend\n\nfunction OBJDEF:encode(value,
    etc, options)\n   if type(self) ~= 'table' or self.__index ~= OBJDEF then\n      OBJDEF:onEncodeError(\"JSON:encode
    must be called in method format\", etc)\n   end\n\n   --\n   -- If the user didn't
    pass in a table of decode options, make an empty one.\n   --\n   if type(options)
    ~= 'table' then\n      options = {}\n   end\n\n   return top_level_encode(self,
    value, etc, options)\nend\n\nfunction OBJDEF:encode_pretty(value, etc, options)\n
    \  if type(self) ~= 'table' or self.__index ~= OBJDEF then\n      OBJDEF:onEncodeError(\"JSON:encode_pretty
    must be called in method format\", etc)\n   end\n\n   --\n   -- If the user didn't
    pass in a table of decode options, use the default pretty ones\n   --\n   if type(options)
    ~= 'table' then\n      options = default_pretty_options\n   end\n\n   return top_level_encode(self,
    value, etc, options)\nend\n\nfunction OBJDEF.__tostring()\n   return \"JSON encode/decode
    package\"\nend\n\nOBJDEF.__index = OBJDEF\n\nfunction OBJDEF:new(args)\n   local
    new = { }\n\n   if args then\n      for key, val in pairs(args) do\n         new[key]
    = val\n      end\n   end\n\n   return setmetatable(new, OBJDEF)\nend\n\nreturn
    OBJDEF:new()\n\n--\n-- Version history:\n--\n--   20170927.26   Use option.null
    in decoding as well. Thanks to Max Sindwani for the bump, and sorry to Oliver
    Hitz\n--                 whose first mention of it four years ago was completely
    missed by me.\n--\n--   20170823.25   Added support for JSON:unsupportedTypeEncoder().\n--
    \                Thanks to Chronos Phaenon Eosphoros (https://github.com/cpeosphoros)
    for the idea.\n--\n--   20170819.24   Added support for boolean keys in tables.\n--\n--
    \  20170416.23   Added the \"array_newline\" formatting option suggested by yurenchen
    (http://www.yurenchen.com/)\n--\n--   20161128.22   Added:\n--                   JSON:isString()\n--
    \                  JSON:isNumber()\n--                   JSON:decodeIntegerObjectificationLength\n--
    \                  JSON:decodeDecimalObjectificationLength\n--\n--   20161109.21
    \  Oops, had a small boo-boo in the previous update.\n--\n--   20161103.20   Used
    to silently ignore trailing garbage when decoding. Now fails via JSON:onTrailingGarbage()\n--
    \                http://seriot.ch/parsing_json.php\n--\n--                 Built-in
    error message about \"expected comma or ']'\" had mistakenly referred to '['\n--\n--
    \                Updated the built-in error reporting to refer to bytes rather
    than characters.\n--\n--                 The decode() method no longer assumes
    that error handlers abort.\n--\n--                 Made the VERSION string a string
    instead of a number\n--\n\n--   20160916.19   Fixed the isNumber.__index assignment
    (thanks to Jack Taylor)\n--   \n--   20160730.18   Added JSON:forceString() and
    JSON:forceNumber()\n--\n--   20160728.17   Added concatenation to the metatable
    for JSON:asNumber()\n--\n--   20160709.16   Could crash if not passed an options
    table (thanks jarno heikkinen <jarnoh@capturemonkey.com>).\n--\n--                 Made
    JSON:asNumber() a bit more resilient to being passed the results of itself.\n--\n--
    \  20160526.15   Added the ability to easily encode null values in JSON, via the
    new \"null\" encoding option.\n--                 (Thanks to Adam B for bringing
    up the issue.)\n--\n--                 Added some support for very large numbers
    and precise floats via\n--                    JSON.decodeNumbersAsObjects\n--
    \                   JSON.decodeIntegerStringificationLength\n--                    JSON.decodeDecimalStringificationLength\n--\n--
    \                Added the \"stringsAreUtf8\" encoding option. (Hat tip to http://lua-users.org/wiki/JsonModules
    )\n--\n--   20141223.14   The encode_pretty() routine produced fine results for
    small datasets, but isn't really\n--                 appropriate for anything
    large, so with help from Alex Aulbach I've made the encode routines\n--                 more
    flexible, and changed the default encode_pretty() to be more generally useful.\n--\n--
    \                Added a third 'options' argument to the encode() and encode_pretty()
    routines, to control\n--                 how the encoding takes place.\n--\n--
    \                Updated docs to add assert() call to the loadfile() line, just
    as good practice so that\n--                 if there is a problem loading JSON.lua,
    the appropriate error message will percolate up.\n--\n--   20140920.13   Put back
    (in a way that doesn't cause warnings about unused variables) the author string,\n--
    \                so that the source of the package, and its version number, are
    visible in compiled copies.\n--\n--   20140911.12   Minor lua cleanup.\n--                 Fixed
    internal reference to 'JSON.noKeyConversion' to reference 'self' instead of 'JSON'.\n--
    \                (Thanks to SmugMug's David Parry for these.)\n--\n--   20140418.11
    \  JSON nulls embedded within an array were being ignored, such that\n--                     [\"1\",null,null,null,null,null,\"seven\"],\n--
    \                would return\n--                     {1,\"seven\"}\n--                 It's
    now fixed to properly return\n--                     {1, nil, nil, nil, nil, nil,
    \"seven\"}\n--                 Thanks to \"haddock\" for catching the error.\n--\n--
    \  20140116.10   The user's JSON.assert() wasn't always being used. Thanks to
    \"blue\" for the heads up.\n--\n--   20131118.9    Update for Lua 5.3... it seems
    that tostring(2/1) produces \"2.0\" instead of \"2\",\n--                 and
    this caused some problems.\n--\n--   20131031.8    Unified the code for encode()
    and encode_pretty(); they had been stupidly separate,\n--                 and
    had of course diverged (encode_pretty didn't get the fixes that encode got, so\n--
    \                sometimes produced incorrect results; thanks to Mattie for the
    heads up).\n--\n--                 Handle encoding tables with non-positive numeric
    keys (unlikely, but possible).\n--\n--                 If a table has both numeric
    and string keys, or its numeric keys are inappropriate\n--                 (such
    as being non-positive or infinite), the numeric keys are turned into\n--                 string
    keys appropriate for a JSON object. So, as before,\n--                         JSON:encode({
    \"one\", \"two\", \"three\" })\n--                 produces the array\n--                         [\"one\",\"two\",\"three\"]\n--
    \                but now something with mixed key types like\n--                         JSON:encode({
    \"one\", \"two\", \"three\", SOMESTRING = \"some string\" }))\n--                 instead
    of throwing an error produces an object:\n--                         {\"1\":\"one\",\"2\":\"two\",\"3\":\"three\",\"SOMESTRING\":\"some
    string\"}\n--\n--                 To maintain the prior throw-an-error semantics,
    set\n--                      JSON.noKeyConversion = true\n--                 \n--
    \  20131004.7    Release under a Creative Commons CC-BY license, which I should
    have done from day one, sorry.\n--\n--   20130120.6    Comment update: added a
    link to the specific page on my blog where this code can\n--                 be
    found, so that folks who come across the code outside of my blog can find updates\n--
    \                more easily.\n--\n--   20111207.5    Added support for the 'etc'
    arguments, for better error reporting.\n--\n--   20110731.4    More feedback from
    David Kolf on how to make the tests for Nan/Infinity system independent.\n--\n--
    \  20110730.3    Incorporated feedback from David Kolf at http://lua-users.org/wiki/JsonModules:\n--\n--
    \                  * When encoding lua for JSON, Sparse numeric arrays are now
    handled by\n--                     spitting out full arrays, such that\n--                        JSON:encode({\"one\",
    \"two\", [10] = \"ten\"})\n--                     returns\n--                        [\"one\",\"two\",null,null,null,null,null,null,null,\"ten\"]\n--\n--
    \                    In 20100810.2 and earlier, only up to the first non-null
    value would have been retained.\n--\n--                   * When encoding lua
    for JSON, numeric value NaN gets spit out as null, and infinity as \"1+e9999\".\n--
    \                    Version 20100810.2 and earlier created invalid JSON in both
    cases.\n--\n--                   * Unicode surrogate pairs are now detected when
    decoding JSON.\n--\n--   20100810.2    added some checking to ensure that an invalid
    Unicode character couldn't leak in to the UTF-8 encoding\n--\n--   20100731.1
    \   initial public release\n--\n"
  pprint.lua: |
    local pprint = { VERSION = '0.1' }

    local depth = 1

    pprint.defaults = {
        -- If set to number N, then limit table recursion to N deep.
        depth_limit = false,
        -- type display trigger, hide not useful datatypes by default
        -- custom types are treated as table
        show_nil = true,
        show_boolean = true,
        show_number = true,
        show_string = true,
        show_table = true,
        show_function = false,
        show_thread = false,
        show_userdata = false,
        -- additional display trigger
        show_metatable = false,     -- show metatable
        show_all = false,           -- override other show settings and show everything
        use_tostring = false,       -- use __tostring to print table if available
        filter_function = nil,      -- called like callback(value[,key, parent]), return truty value to hide
        object_cache = 'local',     -- cache blob and table to give it a id, 'local' cache per print, 'global' cache
                                    -- per process, falsy value to disable (might cause infinite loop)
        -- format settings
        indent_size = 2,            -- indent for each nested table level
        level_width = 80,           -- max width per indent level
        wrap_string = true,         -- wrap string when it's longer than level_width
        wrap_array = false,         -- wrap every array elements
        sort_keys = true,           -- sort table keys
    }

    local TYPES = {
        ['nil'] = 1, ['boolean'] = 2, ['number'] = 3, ['string'] = 4, 
        ['table'] = 5, ['function'] = 6, ['thread'] = 7, ['userdata'] = 8
    }

    -- seems this is the only way to escape these, as lua don't know how to map char '\a' to 'a'
    local ESCAPE_MAP = {
        ['\a'] = '\\a', ['\b'] = '\\b', ['\f'] = '\\f', ['\n'] = '\\n', ['\r'] = '\\r',
        ['\t'] = '\\t', ['\v'] = '\\v', ['\\'] = '\\\\',
    }

    -- generic utilities
    local function escape(s)
        s = s:gsub('([%c\\])', ESCAPE_MAP)
        local dq = s:find('"') 
        local sq = s:find("'")
        if dq and sq then
            return s:gsub('"', '\\"'), '"'
        elseif sq then
            return s, '"'
        else
            return s, "'"
        end
    end

    local function is_plain_key(key)
        return type(key) == 'string' and key:match('^[%a_][%a%d_]*$')
    end

    local CACHE_TYPES = {
        ['table'] = true, ['function'] = true, ['thread'] = true, ['userdata'] = true
    }

    -- cache would be populated to be like:
    -- {
    --     function = { `fun1` = 1, _cnt = 1 }, -- object id
    --     table = { `table1` = 1, `table2` = 2, _cnt = 2 },
    --     visited_tables = { `table1` = 7, `table2` = 8  }, -- visit count
    -- }
    -- use weakrefs to avoid accidentall adding refcount
    local function cache_apperance(obj, cache, option)
        if not cache.visited_tables then
            cache.visited_tables = setmetatable({}, {__mode = 'k'})
        end
        local t = type(obj)

        -- TODO can't test filter_function here as we don't have the ix and key,
        -- might cause different results?
        -- respect show_xxx and filter_function to be consistent with print results
        if (not TYPES[t] and not option.show_table)
            or (TYPES[t] and not option['show_'..t]) then
            return
        end

        if CACHE_TYPES[t] or TYPES[t] == nil then
            if not cache[t] then
                cache[t] = setmetatable({}, {__mode = 'k'})
                cache[t]._cnt = 0
            end
            if not cache[t][obj] then
                cache[t]._cnt = cache[t]._cnt + 1
                cache[t][obj] = cache[t]._cnt
            end
        end
        if t == 'table' or TYPES[t] == nil then
            if cache.visited_tables[obj] == false then
                -- already printed, no need to mark this and its children anymore
                return
            elseif cache.visited_tables[obj] == nil then
                cache.visited_tables[obj] = 1
            else
                -- visited already, increment and continue
                cache.visited_tables[obj] = cache.visited_tables[obj] + 1
                return
            end
            for k, v in pairs(obj) do
                cache_apperance(k, cache, option)
                cache_apperance(v, cache, option)
            end
            local mt = getmetatable(obj)
            if mt and option.show_metatable then
                cache_apperance(mt, cache, option)
            end
        end
    end

    -- makes 'foo2' < 'foo100000'. string.sub makes substring anyway, no need to use index based method
    local function str_natural_cmp(lhs, rhs)
        while #lhs > 0 and #rhs > 0 do
            local lmid, lend = lhs:find('%d+')
            local rmid, rend = rhs:find('%d+')
            if not (lmid and rmid) then return lhs < rhs end

            local lsub = lhs:sub(1, lmid-1)
            local rsub = rhs:sub(1, rmid-1)
            if lsub ~= rsub then
                return lsub < rsub
            end

            local lnum = tonumber(lhs:sub(lmid, lend))
            local rnum = tonumber(rhs:sub(rmid, rend))
            if lnum ~= rnum then
                return lnum < rnum
            end

            lhs = lhs:sub(lend+1)
            rhs = rhs:sub(rend+1)
        end
        return lhs < rhs
    end

    local function cmp(lhs, rhs)
        local tleft = type(lhs)
        local tright = type(rhs)
        if tleft == 'number' and tright == 'number' then return lhs < rhs end
        if tleft == 'string' and tright == 'string' then return str_natural_cmp(lhs, rhs) end
        if tleft == tright then return str_natural_cmp(tostring(lhs), tostring(rhs)) end

        -- allow custom types
        local oleft = TYPES[tleft] or 9
        local oright = TYPES[tright] or 9
        return oleft < oright
    end

    -- setup option with default
    local function make_option(option)
        if option == nil then
            option = {}
        end
        for k, v in pairs(pprint.defaults) do
            if option[k] == nil then
                option[k] = v
            end
            if option.show_all then
                for t, _ in pairs(TYPES) do
                    option['show_'..t] = true
                end
                option.show_metatable = true
            end
        end
        return option
    end

    -- override defaults and take effects for all following calls
    function pprint.setup(option)
        pprint.defaults = make_option(option)
    end

    -- format lua object into a string
    function pprint.pformat(obj, option, printer)
        option = make_option(option)
        local buf = {}
        local function default_printer(s)
            table.insert(buf, s)
        end
        printer = printer or default_printer

        local cache
        if option.object_cache == 'global' then
            -- steal the cache into a local var so it's not visible from _G or anywhere
            -- still can't avoid user explicitly referentce pprint._cache but it shouldn't happen anyway
            cache = pprint._cache or {}
            pprint._cache = nil
        elseif option.object_cache == 'local' then
            cache = {}
        end

        local last = '' -- used for look back and remove trailing comma
        local status = {
            indent = '', -- current indent
            len = 0,     -- current line length
        }

        local wrapped_printer = function(s)
            printer(last)
            last = s
        end

        local function _indent(d)
            status.indent = string.rep(' ', d + #(status.indent))
        end

        local function _n(d)
            wrapped_printer('\n')
            wrapped_printer(status.indent)
            if d then
                _indent(d)
            end
            status.len = 0
            return true -- used to close bracket correctly
        end

        local function _p(s, nowrap)
            status.len = status.len + #s
            if not nowrap and status.len > option.level_width then
                _n()
                wrapped_printer(s)
                status.len = #s
            else
                wrapped_printer(s)
            end
        end

        local formatter = {}
        local function format(v)
            local f = formatter[type(v)]
            f = f or formatter.table -- allow patched type()
            if option.filter_function and option.filter_function(v, nil, nil) then
                return ''
            else
                return f(v)
            end
        end

        local function tostring_formatter(v)
            return tostring(v)
        end

        local function number_formatter(n)
            return n == math.huge and '[[math.huge]]' or tostring(n)
        end

        local function nop_formatter(v)
            return ''
        end

        local function make_fixed_formatter(t, has_cache)
            if has_cache then
                return function (v)
                    return string.format('[[%s %d]]', t, cache[t][v])
                end
            else
                return function (v)
                    return '[['..t..']]'
                end
            end
        end

        local function string_formatter(s, force_long_quote)
            local s, quote = escape(s)
            local quote_len = force_long_quote and 4 or 2
            if quote_len + #s + status.len > option.level_width then
                _n()
                -- only wrap string when is longer than level_width
                if option.wrap_string and #s + quote_len > option.level_width then
                    -- keep the quotes together
                    _p('[[')
                    while #s + status.len >= option.level_width do
                        local seg = option.level_width - status.len
                        _p(string.sub(s, 1, seg), true)
                        _n()
                        s = string.sub(s, seg+1)
                    end
                    _p(s) -- print the remaining parts
                    return ']]' 
                end
            end

            return force_long_quote and '[['..s..']]' or quote..s..quote
        end

        local function table_formatter(t)
            if option.use_tostring then
                local mt = getmetatable(t)
                if mt and mt.__tostring then
                    return string_formatter(tostring(t), true)
                end
            end

            local print_header_ix = nil
            local ttype = type(t)
            if option.object_cache then
                local cache_state = cache.visited_tables[t]
                local tix = cache[ttype][t]
                -- FIXME should really handle `cache_state == nil`
                -- as user might add things through filter_function
                if cache_state == false then
                    -- already printed, just print the the number
                    return string_formatter(string.format('%s %d', ttype, tix), true)
                elseif cache_state > 1 then
                    -- appeared more than once, print table header with number
                    print_header_ix = tix
                    cache.visited_tables[t] = false
                else
                    -- appeared exactly once, print like a normal table
                end
            end

            local limit = tonumber(option.depth_limit)
            if limit and depth > limit then
               if print_header_ix then
                  return string.format('[[%s %d]]...', ttype, print_header_ix)
               end
               return string_formatter(tostring(t), true)
            end

            local tlen = #t
            local wrapped = false
            _p('{')
            _indent(option.indent_size)
            _p(string.rep(' ', option.indent_size - 1))
            if print_header_ix then
                _p(string.format('--[[%s %d]] ', ttype, print_header_ix))
            end
            for ix = 1,tlen do
                local v = t[ix]
                if formatter[type(v)] == nop_formatter or 
                   (option.filter_function and option.filter_function(v, ix, t)) then
                   -- pass
                else
                    if option.wrap_array then
                        wrapped = _n()
                    end
                    depth = depth+1
                    _p(format(v)..', ')
                    depth = depth-1
                end
            end

            -- hashmap part of the table, in contrast to array part
            local function is_hash_key(k)
                if type(k) ~= 'number' then
                    return true
                end

                local numkey = math.floor(tonumber(k))
                if numkey ~= k or numkey > tlen or numkey <= 0 then
                    return true
                end
            end

            local function print_kv(k, v, t)
                -- can't use option.show_x as obj may contain custom type
                if formatter[type(v)] == nop_formatter or
                   formatter[type(k)] == nop_formatter or 
                   (option.filter_function and option.filter_function(v, k, t)) then
                    return
                end
                wrapped = _n()
                if is_plain_key(k) then
                    _p(k, true)
                else
                    _p('[')
                    -- [[]] type string in key is illegal, needs to add spaces inbetween
                    local k = format(k)
                    if string.match(k, '%[%[') then
                        _p(' '..k..' ', true)
                    else
                        _p(k, true)
                    end
                    _p(']')
                end
                _p(' = ', true)
                depth = depth+1
                _p(format(v), true)
                depth = depth-1
                _p(',', true)
            end

            if option.sort_keys then
                local keys = {}
                for k, _ in pairs(t) do
                    if is_hash_key(k) then
                        table.insert(keys, k)
                    end
                end
                table.sort(keys, cmp)
                for _, k in ipairs(keys) do
                    print_kv(k, t[k], t)
                end
            else
                for k, v in pairs(t) do
                    if is_hash_key(k) then
                        print_kv(k, v, t)
                    end
                end
            end

            if option.show_metatable then
                local mt = getmetatable(t)
                if mt then
                    print_kv('__metatable', mt, t)
                end
            end

            _indent(-option.indent_size)
            -- make { } into {}
            last = string.gsub(last, '^ +$', '')
            -- peek last to remove trailing comma
            last = string.gsub(last, ',%s*$', ' ')
            if wrapped then
                _n()
            end
            _p('}')

            return ''
        end

        -- set formatters
        formatter['nil'] = option.show_nil and tostring_formatter or nop_formatter
        formatter['boolean'] = option.show_boolean and tostring_formatter or nop_formatter
        formatter['number'] = option.show_number and number_formatter or nop_formatter -- need to handle math.huge
        formatter['function'] = option.show_function and make_fixed_formatter('function', option.object_cache) or nop_formatter
        formatter['thread'] = option.show_thread and make_fixed_formatter('thread', option.object_cache) or nop_formatter
        formatter['userdata'] = option.show_userdata and make_fixed_formatter('userdata', option.object_cache) or nop_formatter
        formatter['string'] = option.show_string and string_formatter or nop_formatter
        formatter['table'] = option.show_table and table_formatter or nop_formatter

        if option.object_cache then
            -- needs to visit the table before start printing
            cache_apperance(obj, cache, option)
        end

        _p(format(obj))
        printer(last) -- close the buffered one

        -- put cache back if global
        if option.object_cache == 'global' then
            pprint._cache = cache
        end

        return table.concat(buf)
    end

    -- pprint all the arguments
    function pprint.pprint( ... )
        local args = {...}
        -- select will get an accurate count of array len, counting trailing nils
        local len = select('#', ...)
        for ix = 1,len do
            pprint.pformat(args[ix], nil, io.write)
            io.write('\n')
        end
    end

    setmetatable(pprint, {
        __call = function (_, ...)
            pprint.pprint(...)
        end
    })

    return pprint
  url.lua: |
    -- net/url.lua - a robust url parser and builder
    --
    -- Bertrand Mansion, 2011-2021; License MIT
    -- @module net.url
    -- @alias	M

    local M = {}
    M.version = "1.1.0"

    --- url options
    -- - `separator` is set to `&` by default but could be anything like `&amp;amp;` or `;`
    -- - `cumulative_parameters` is false by default. If true, query parameters with the same name will be stored in a table.
    -- - `legal_in_path` is a table of characters that will not be url encoded in path components
    -- - `legal_in_query` is a table of characters that will not be url encoded in query values. Query parameters only support a small set of legal characters (-_.).
    -- - `query_plus_is_space` is true by default, so a plus sign in a query value will be converted to %20 (space), not %2B (plus)
    -- @todo Add option to limit the size of the argument table
    -- @todo Add option to limit the depth of the argument table
    -- @todo Add option to process dots in parameter names, ie. `param.filter=1`
    M.options = {
    	separator = '&',
    	cumulative_parameters = false,
    	legal_in_path = {
    		[":"] = true, ["-"] = true, ["_"] = true, ["."] = true,
    		["!"] = true, ["~"] = true, ["*"] = true, ["'"] = true,
    		["("] = true, [")"] = true, ["@"] = true, ["&"] = true,
    		["="] = true, ["$"] = true, [","] = true,
    		[";"] = true
    	},
    	legal_in_query = {
    		[":"] = true, ["-"] = true, ["_"] = true, ["."] = true,
    		[","] = true, ["!"] = true, ["~"] = true, ["*"] = true,
    		["'"] = true, [";"] = true, ["("] = true, [")"] = true,
    		["@"] = true, ["$"] = true,
    	},
    	query_plus_is_space = true
    }

    --- list of known and common scheme ports
    -- as documented in <a href="http://www.iana.org/assignments/uri-schemes.html">IANA URI scheme list</a>
    M.services = {
    	acap     = 674,
    	cap      = 1026,
    	dict     = 2628,
    	ftp      = 21,
    	gopher   = 70,
    	http     = 80,
    	https    = 443,
    	iax      = 4569,
    	icap     = 1344,
    	imap     = 143,
    	ipp      = 631,
    	ldap     = 389,
    	mtqp     = 1038,
    	mupdate  = 3905,
    	news     = 2009,
    	nfs      = 2049,
    	nntp     = 119,
    	rtsp     = 554,
    	sip      = 5060,
    	snmp     = 161,
    	telnet   = 23,
    	tftp     = 69,
    	vemmi    = 575,
    	afs      = 1483,
    	jms      = 5673,
    	rsync    = 873,
    	prospero = 191,
    	videotex = 516
    }

    local function decode(str)
    	return (str:gsub("%%(%x%x)", function(c)
    		return string.char(tonumber(c, 16))
    	end))
    end

    local function encode(str, legal)
    	return (str:gsub("([^%w])", function(v)
    		if legal[v] then
    			return v
    		end
    		return string.upper(string.format("%%%02x", string.byte(v)))
    	end))
    end

    -- for query values, + can mean space if configured as such
    local function decodeValue(str)
    	if M.options.query_plus_is_space then
    		str = str:gsub('+', ' ')
    	end
    	return decode(str)
    end

    local function concat(a, b)
    	if type(a) == 'table' then
    		return a:build() .. b
    	else
    		return a .. b:build()
    	end
    end

    function M:addSegment(path)
    	if type(path) == 'string' then
    		self.path = self.path .. '/' .. encode(path:gsub("^/+", ""), M.options.legal_in_path)
    	end
    	return self
    end

    --- builds the url
    -- @return a string representing the built url
    function M:build()
    	local url = ''
    	if self.path then
    		local path = self.path
    		url = url .. tostring(path)
    	end
    	if self.query then
    		local qstring = tostring(self.query)
    		if qstring ~= "" then
    			url = url .. '?' .. qstring
    		end
    	end
    	if self.host then
    		local authority = self.host
    		if self.port and self.scheme and M.services[self.scheme] ~= self.port then
    			authority = authority .. ':' .. self.port
    		end
    		local userinfo
    		if self.user and self.user ~= "" then
    			userinfo = self.user
    			if self.password then
    				userinfo = userinfo .. ':' .. self.password
    			end
    		end
    		if userinfo and userinfo ~= "" then
    			authority = userinfo .. '@' .. authority
    		end
    		if authority then
    			if url ~= "" then
    				url = '//' .. authority .. '/' .. url:gsub('^/+', '')
    			else
    				url = '//' .. authority
    			end
    		end
    	end
    	if self.scheme then
    		url = self.scheme .. ':' .. url
    	end
    	if self.fragment then
    		url = url .. '#' .. self.fragment
    	end
    	return url
    end

    --- builds the querystring
    -- @param tab The key/value parameters
    -- @param sep The separator to use (optional)
    -- @param key The parent key if the value is multi-dimensional (optional)
    -- @return a string representing the built querystring
    function M.buildQuery(tab, sep, key)
    	local query = {}
    	if not sep then
    		sep = M.options.separator or '&'
    	end
    	local keys = {}
    	for k in pairs(tab) do
    		keys[#keys+1] = k
    	end
    	table.sort(keys, function (a, b)
      		local function padnum(n, rest) return ("%03d"..rest):format(tonumber(n)) end
      		return tostring(a):gsub("(%d+)(%.)",padnum) < tostring(b):gsub("(%d+)(%.)",padnum)
    	end)
    	for _,name in ipairs(keys) do
    		local value = tab[name]
    		name = encode(tostring(name), {["-"] = true, ["_"] = true, ["."] = true})
    		if key then
    			if M.options.cumulative_parameters and string.find(name, '^%d+$') then
    				name = tostring(key)
    			else
    				name = string.format('%s[%s]', tostring(key), tostring(name))
    			end
    		end
    		if type(value) == 'table' then
    			query[#query+1] = M.buildQuery(value, sep, name)
    		else
    			local value = encode(tostring(value), M.options.legal_in_query)
    			if value ~= "" then
    				query[#query+1] = string.format('%s=%s', name, value)
    			else
    				query[#query+1] = name
    			end
    		end
    	end
    	return table.concat(query, sep)
    end

    --- Parses the querystring to a table
    -- This function can parse multidimensional pairs and is mostly compatible
    -- with PHP usage of brackets in key names like ?param[key]=value
    -- @param str The querystring to parse
    -- @param sep The separator between key/value pairs, defaults to `&`
    -- @todo limit the max number of parameters with M.options.max_parameters
    -- @return a table representing the query key/value pairs
    function M.parseQuery(str, sep)
    	if not sep then
    		sep = M.options.separator or '&'
    	end

    	local values = {}
    	for key,val in str:gmatch(string.format('([^%q=]+)(=*[^%q=]*)', sep, sep)) do
    		local key = decodeValue(key)
    		local keys = {}
    		key = key:gsub('%[([^%]]*)%]', function(v)
    				-- extract keys between balanced brackets
    				if string.find(v, "^-?%d+$") then
    					v = tonumber(v)
    				else
    					v = decodeValue(v)
    				end
    				table.insert(keys, v)
    				return "="
    		end)
    		key = key:gsub('=+.*$', "")
    		key = key:gsub('%s', "_") -- remove spaces in parameter name
    		val = val:gsub('^=+', "")

    		if not values[key] then
    			values[key] = {}
    		end
    		if #keys > 0 and type(values[key]) ~= 'table' then
    			values[key] = {}
    		elseif #keys == 0 and type(values[key]) == 'table' then
    			values[key] = decodeValue(val)
    		elseif M.options.cumulative_parameters
    			and type(values[key]) == 'string' then
    			values[key] = { values[key] }
    			table.insert(values[key], decodeValue(val))
    		end

    		local t = values[key]
    		for i,k in ipairs(keys) do
    			if type(t) ~= 'table' then
    				t = {}
    			end
    			if k == "" then
    				k = #t+1
    			end
    			if not t[k] then
    				t[k] = {}
    			end
    			if i == #keys then
    				t[k] = val
    			end
    			t = t[k]
    		end

    	end
    	setmetatable(values, { __tostring = M.buildQuery })
    	return values
    end

    --- set the url query
    -- @param query Can be a string to parse or a table of key/value pairs
    -- @return a table representing the query key/value pairs
    function M:setQuery(query)
    	local query = query
    	if type(query) == 'table' then
    		query = M.buildQuery(query)
    	end
    	self.query = M.parseQuery(query)
    	return query
    end

    --- set the authority part of the url
    -- The authority is parsed to find the user, password, port and host if available.
    -- @param authority The string representing the authority
    -- @return a string with what remains after the authority was parsed
    function M:setAuthority(authority)
    	self.authority = authority
    	self.port = nil
    	self.host = nil
    	self.userinfo = nil
    	self.user = nil
    	self.password = nil

    	authority = authority:gsub('^([^@]*)@', function(v)
    		self.userinfo = v
    		return ''
    	end)

    	authority = authority:gsub(':(%d+)$', function(v)
    		self.port = tonumber(v)
    		return ''
    	end)

    	local function getIP(str)
    		-- ipv4
    		local chunks = { str:match("^(%d+)%.(%d+)%.(%d+)%.(%d+)$") }
    		if #chunks == 4 then
    			for _, v in pairs(chunks) do
    				if tonumber(v) > 255 then
    					return false
    				end
    			end
    			return str
    		end
    		-- ipv6
    		local chunks = { str:match("^%["..(("([a-fA-F0-9]*):"):rep(8):gsub(":$","%%]$"))) }
    		if #chunks == 8 or #chunks < 8 and
    			str:match('::') and not str:gsub("::", "", 1):match('::') then
    			for _,v in pairs(chunks) do
    				if #v > 0 and tonumber(v, 16) > 65535 then
    					return false
    				end
    			end
    			return str
    		end
    		return nil
    	end

    	local ip = getIP(authority)
    	if ip then
    		self.host = ip
    	elseif type(ip) == 'nil' then
    		-- domain
    		if authority ~= '' and not self.host then
    			local host = authority:lower()
    			if  string.match(host, '^[%d%a%-%.]+$') ~= nil and
    				string.sub(host, 0, 1) ~= '.' and
    				string.sub(host, -1) ~= '.' and
    				string.find(host, '%.%.') == nil then
    				self.host = host
    			end
    		end
    	end

    	if self.userinfo then
    		local userinfo = self.userinfo
    		userinfo = userinfo:gsub(':([^:]*)$', function(v)
    				self.password = v
    				return ''
    		end)
    		if string.find(userinfo, "^[%w%+%.]+$") then
    			self.user = userinfo
    		else
    			-- incorrect userinfo
    			self.userinfo = nil
    			self.user = nil
    			self.password = nil
    		end
    	end

    	return authority
    end

    --- Parse the url into the designated parts.
    -- Depending on the url, the following parts can be available:
    -- scheme, userinfo, user, password, authority, host, port, path,
    -- query, fragment
    -- @param url Url string
    -- @return a table with the different parts and a few other functions
    function M.parse(url)
    	local comp = {}
    	M.setAuthority(comp, "")
    	M.setQuery(comp, "")

    	local url = tostring(url or '')
    	url = url:gsub('#(.*)$', function(v)
    		comp.fragment = v
    		return ''
    	end)
    	url =url:gsub('^([%w][%w%+%-%.]*)%:', function(v)
    		comp.scheme = v:lower()
    		return ''
    	end)
    	url = url:gsub('%?(.*)', function(v)
    		M.setQuery(comp, v)
    		return ''
    	end)
    	url = url:gsub('^//([^/]*)', function(v)
    		M.setAuthority(comp, v)
    		return ''
    	end)

    	comp.path = url:gsub("([^/]+)", function (s) return encode(decode(s), M.options.legal_in_path) end)

    	setmetatable(comp, {
    		__index = M,
    		__tostring = M.build,
    		__concat = concat,
    		__div = M.addSegment
    	})
    	return comp
    end

    --- removes dots and slashes in urls when possible
    -- This function will also remove multiple slashes
    -- @param path The string representing the path to clean
    -- @return a string of the path without unnecessary dots and segments
    function M.removeDotSegments(path)
    	local fields = {}
    	if string.len(path) == 0 then
    		return ""
    	end
    	local startslash = false
    	local endslash = false
    	if string.sub(path, 1, 1) == "/" then
    		startslash = true
    	end
    	if (string.len(path) > 1 or startslash == false) and string.sub(path, -1) == "/" then
    		endslash = true
    	end

    	path:gsub('[^/]+', function(c) table.insert(fields, c) end)

    	local new = {}
    	local j = 0

    	for i,c in ipairs(fields) do
    		if c == '..' then
    			if j > 0 then
    				j = j - 1
    			end
    		elseif c ~= "." then
    			j = j + 1
    			new[j] = c
    		end
    	end
    	local ret = ""
    	if #new > 0 and j > 0 then
    		ret = table.concat(new, '/', 1, j)
    	else
    		ret = ""
    	end
    	if startslash then
    		ret = '/'..ret
    	end
    	if endslash then
    		ret = ret..'/'
    	end
    	return ret
    end

    local function reducePath(base_path, relative_path)
    	if string.sub(relative_path, 1, 1) == "/" then
    		return '/' .. string.gsub(relative_path, '^[%./]+', '')
    	end
    	local path = base_path
    	local startslash = string.sub(path, 1, 1) ~= "/";
    	if relative_path ~= "" then
    		path = (startslash and '' or '/') .. path:gsub("[^/]*$", "")
    	end
    	path = path .. relative_path
    	path = path:gsub("([^/]*%./)", function (s)
    		if s ~= "./" then return s else return "" end
    	end)
    	path = string.gsub(path, "/%.$", "/")
    	local reduced
    	while reduced ~= path do
    		reduced = path
    		path = string.gsub(reduced, "([^/]*/%.%./)", function (s)
    			if s ~= "../../" then return "" else return s end
    		end)
    	end
    	path = string.gsub(path, "([^/]*/%.%.?)$", function (s)
    		if s ~= "../.." then return "" else return s end
    	end)
    	local reduced
    	while reduced ~= path do
    		reduced = path
    		path = string.gsub(reduced, '^/?%.%./', '')
    	end
    	return (startslash and '' or '/') .. path
    end

    --- builds a new url by using the one given as parameter and resolving paths
    -- @param other A string or a table representing a url
    -- @return a new url table
    function M:resolve(other)
    	if type(self) == "string" then
    		self = M.parse(self)
    	end
    	if type(other) == "string" then
    		other = M.parse(other)
    	end
    	if other.scheme then
    		return other
    	else
    		other.scheme = self.scheme
    		if not other.authority or other.authority == "" then
    			other:setAuthority(self.authority)
    			if not other.path or other.path == "" then
    				other.path = self.path
    				local query = other.query
    				if not query or not next(query) then
    					other.query = self.query
    				end
    			else
    				other.path = reducePath(self.path, other.path)
    			end
    		end
    		return other
    	end
    end

    --- normalize a url path following some common normalization rules
    -- described on <a href="http://en.wikipedia.org/wiki/URL_normalization">The URL normalization page of Wikipedia</a>
    -- @return the normalized path
    function M:normalize()
    	if type(self) == 'string' then
    		self = M.parse(self)
    	end
    	if self.path then
    		local path = self.path
    		path = reducePath(path, "")
    		-- normalize multiple slashes
    		path = string.gsub(path, "//+", "/")
    		self.path = path
    	end
    	return self
    end

    return M